<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=generator content="Wowchemy 5.3.0 for Hugo">
<meta name=author content="Peipei Zhou">
<meta name=description content="As AI continues to grow, modern applications are becoming more data- and compute-intensive, driving the development of specialized AI chips to meet these demands. One example is AMD's AI Engine (AIE), a dedicated hardware system that includes a 2D array of high-frequency very-long instruction words (VLIW) vector processors to provide high computational throughput and reconfigurability. However, AIE's specialized architecture presents tremendous challenges in programming and compiler optimization. Existing AIE programming frameworks lack a clean abstraction to represent multi-level parallelism in AIE; programmers have to figure out the parallelism within a kernel, manually do the partition, and assign sub-tasks to different AIE cores to exploit parallelism. These significantly lower the programming productivity. Furthermore, some AIE architectures include FPGAs to provide extra flexibility, but there is no unified intermediate representation (IR) that captures these architectural differences. As a result, existing compilers can only optimize the AIE portions of the code, overlooking potential FPGA bottlenecks and leading to suboptimal performance. 

To address these limitations, we introduce ARIES, an agile multilevel intermediate representation (MLIR) based compilation flow for reconfigurable devices with AIEs. ARIES introduces a novel programming model that allows users to map kernels to separate AIE cores, exploiting task- and tile-level parallelism without restructuring code. It also includes a declarative scheduling interface to explore instruction-level parallelism within each core. At the IR level, we propose a unified MLIR-based representation for AIE architectures, both with or without FPGA, facilitating holistic optimization and better portability across AIE device families. For the General Matrix Multiply (GEMM) benchmark, ARIES achieves 4.92 TFLOPS, 15.86 TOPS, and 45.94 TOPS throughput under FP32, INT16, and, INT8 data types on Versal VCK190 respectively. Compared with the state-of-the-art (SOTA) work CHARM for AIE, ARIES improves the throughput by 1.17x, 1.59x, and 1.47x correspondingly. For ResNet residual layer, ARIES achieves up to 22.58x speedup compared with optimized SOTA work Riallto on Ryzen-AI NPU. ARIES is opensourced on GitHub: https://github.com/arc-research-lab/Aries.">
<link rel=alternate hreflang=en-us href=https://peipeizhou-eecs.github.io/publication/2025_fpga_aries/>
<link rel=preconnect href=https://fonts.gstatic.com crossorigin>
<meta name=theme-color content="#1565c0">
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload="this.media='all'" disabled>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin=anonymous media=print onload="this.media='all'">
<link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
<link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload="this.media='all'">
<link rel=stylesheet href=/css/wowchemy.f0cf03b20998d63e314819fa4a90c13f.css>
<link rel=manifest href=/manifest.webmanifest>
<link rel=icon type=image/png href=/media/icon_hu1250aaa54d869e747b2648a1402f0494_97654_32x32_fill_lanczos_center_3.png>
<link rel=apple-touch-icon type=image/png href=/media/icon_hu1250aaa54d869e747b2648a1402f0494_97654_180x180_fill_lanczos_center_3.png>
<link rel=canonical href=https://peipeizhou-eecs.github.io/publication/2025_fpga_aries/>
<meta property="twitter:card" content="summary">
<meta property="og:site_name" content="Peipei Zhou's Homepage">
<meta property="og:url" content="https://peipeizhou-eecs.github.io/publication/2025_fpga_aries/">
<meta property="og:title" content="ARIES: An Agile MLIR-Based Compilation Flow for Reconfigurable Devices with AI Engines(ðŸ”¥ðŸ“£ FPGA 2025 Best Paper CandidateðŸ”¥ðŸ“£! ) | Peipei Zhou's Homepage">
<meta property="og:description" content="As AI continues to grow, modern applications are becoming more data- and compute-intensive, driving the development of specialized AI chips to meet these demands. One example is AMD's AI Engine (AIE), a dedicated hardware system that includes a 2D array of high-frequency very-long instruction words (VLIW) vector processors to provide high computational throughput and reconfigurability. However, AIE's specialized architecture presents tremendous challenges in programming and compiler optimization. Existing AIE programming frameworks lack a clean abstraction to represent multi-level parallelism in AIE; programmers have to figure out the parallelism within a kernel, manually do the partition, and assign sub-tasks to different AIE cores to exploit parallelism. These significantly lower the programming productivity. Furthermore, some AIE architectures include FPGAs to provide extra flexibility, but there is no unified intermediate representation (IR) that captures these architectural differences. As a result, existing compilers can only optimize the AIE portions of the code, overlooking potential FPGA bottlenecks and leading to suboptimal performance. 

To address these limitations, we introduce ARIES, an agile multilevel intermediate representation (MLIR) based compilation flow for reconfigurable devices with AIEs. ARIES introduces a novel programming model that allows users to map kernels to separate AIE cores, exploiting task- and tile-level parallelism without restructuring code. It also includes a declarative scheduling interface to explore instruction-level parallelism within each core. At the IR level, we propose a unified MLIR-based representation for AIE architectures, both with or without FPGA, facilitating holistic optimization and better portability across AIE device families. For the General Matrix Multiply (GEMM) benchmark, ARIES achieves 4.92 TFLOPS, 15.86 TOPS, and 45.94 TOPS throughput under FP32, INT16, and, INT8 data types on Versal VCK190 respectively. Compared with the state-of-the-art (SOTA) work CHARM for AIE, ARIES improves the throughput by 1.17x, 1.59x, and 1.47x correspondingly. For ResNet residual layer, ARIES achieves up to 22.58x speedup compared with optimized SOTA work Riallto on Ryzen-AI NPU. ARIES is opensourced on GitHub: https://github.com/arc-research-lab/Aries."><meta property="og:image" content="https://peipeizhou-eecs.github.io/media/icon_hu1250aaa54d869e747b2648a1402f0494_97654_512x512_fill_lanczos_center_3.png">
<meta property="twitter:image" content="https://peipeizhou-eecs.github.io/media/icon_hu1250aaa54d869e747b2648a1402f0494_97654_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us">
<meta property="article:published_time" content="2025-01-10T00:53:11+00:00">
<meta property="article:modified_time" content="2025-01-10T00:53:11+00:00">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://peipeizhou-eecs.github.io/publication/2025_fpga_aries/"},"headline":"ARIES: An Agile MLIR-Based Compilation Flow for Reconfigurable Devices with AI Engines(ðŸ”¥ðŸ“£ FPGA 2025 Best Paper CandidateðŸ”¥ðŸ“£! )","datePublished":"2025-01-10T00:53:11Z","dateModified":"2025-01-10T00:53:11Z","author":{"@type":"Person","name":"Jinming Zhuang"},"publisher":{"@type":"Organization","name":"Peipei Zhou's Homepage","logo":{"@type":"ImageObject","url":"https://peipeizhou-eecs.github.io/media/icon_hu1250aaa54d869e747b2648a1402f0494_97654_192x192_fill_lanczos_center_3.png"}},"description":"As AI continues to grow, modern applications are becoming more data- and compute-intensive, driving the development of specialized AI chips to meet these demands. One example is AMD's AI Engine (AIE), a dedicated hardware system that includes a 2D array of high-frequency very-long instruction words (VLIW) vector processors to provide high computational throughput and reconfigurability. However, AIE's specialized architecture presents tremendous challenges in programming and compiler optimization. Existing AIE programming frameworks lack a clean abstraction to represent multi-level parallelism in AIE; programmers have to figure out the parallelism within a kernel, manually do the partition, and assign sub-tasks to different AIE cores to exploit parallelism. These significantly lower the programming productivity. Furthermore, some AIE architectures include FPGAs to provide extra flexibility, but there is no unified intermediate representation (IR) that captures these architectural differences. As a result, existing compilers can only optimize the AIE portions of the code, overlooking potential FPGA bottlenecks and leading to suboptimal performance. \n\nTo address these limitations, we introduce ARIES, an agile multilevel intermediate representation (MLIR) based compilation flow for reconfigurable devices with AIEs. ARIES introduces a novel programming model that allows users to map kernels to separate AIE cores, exploiting task- and tile-level parallelism without restructuring code. It also includes a declarative scheduling interface to explore instruction-level parallelism within each core. At the IR level, we propose a unified MLIR-based representation for AIE architectures, both with or without FPGA, facilitating holistic optimization and better portability across AIE device families. For the General Matrix Multiply (GEMM) benchmark, ARIES achieves 4.92 TFLOPS, 15.86 TOPS, and 45.94 TOPS throughput under FP32, INT16, and, INT8 data types on Versal VCK190 respectively. Compared with the state-of-the-art (SOTA) work CHARM for AIE, ARIES improves the throughput by 1.17x, 1.59x, and 1.47x correspondingly. For ResNet residual layer, ARIES achieves up to 22.58x speedup compared with optimized SOTA work Riallto on Ryzen-AI NPU. ARIES is opensourced on GitHub: https://github.com/arc-research-lab/Aries."}</script>
<title>ARIES: An Agile MLIR-Based Compilation Flow for Reconfigurable Devices with AI Engines(ðŸ”¥ðŸ“£ FPGA 2025 Best Paper CandidateðŸ”¥ðŸ“£! ) | Peipei Zhou's Homepage</title>
</head>
<body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=232872d16c52d360d6c1836d93347821>
<script src=/js/wowchemy-init.min.8988fb2a4bba758785868cfcb5244555.js></script>
<aside class=search-modal id=search>
<div class=container>
<section class=search-header>
<div class="row no-gutters justify-content-between mb-3">
<div class=col-6>
<h1>Search</h1>
</div>
<div class="col-6 col-search-close">
<a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a>
</div>
</div>
<div id=search-box>
<input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...>
</div>
</section>
<section class=section-search-results>
<div id=search-hits>
</div>
</section>
</div>
</aside>
<div class=page-header>
<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main>
<div class=container-xl>
<div class="d-none d-lg-inline-flex">
<a class=navbar-brand href=/>Peipei Zhou's Homepage</a>
</div>
<button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span>
</button>
<div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
<a class=navbar-brand href=/>Peipei Zhou's Homepage</a>
</div>
<div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content>
<ul class="navbar-nav d-md-inline-flex">
<li class=nav-item>
<a class=nav-link href=/#about><span>Home</span></a>
</li>
<li class=nav-item>
<a class="nav-link active" href=/publication><span>Publications</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#posts><span>Posts</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#accomplishments><span>Honor</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/uploads/Peipei_Zhou_CV.pdf><span>CV</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#experience><span>Career</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#projects><span>Projects</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/people><span>People</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#talks><span>Talks</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#contact><span>Contact</span></a>
</li>
</ul>
</div>
<ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
<li class=nav-item>
<a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a>
</li>
<li class="nav-item dropdown theme-dropdown">
<a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences">
<i class="fas fa-moon" aria-hidden=true></i>
</a>
<div class=dropdown-menu>
<a href=# class="dropdown-item js-set-theme-light">
<span>Light</span>
</a>
<a href=# class="dropdown-item js-set-theme-dark">
<span>Dark</span>
</a>
<a href=# class="dropdown-item js-set-theme-auto">
<span>Automatic</span>
</a>
</div>
</li>
</ul>
</div>
</nav>
</div>
<div class=page-body>
<div class=pub>
<div class="article-container pt-3">
<h1>ARIES: An Agile MLIR-Based Compilation Flow for Reconfigurable Devices with AI Engines(ðŸ”¥ðŸ“£ FPGA 2025 Best Paper CandidateðŸ”¥ðŸ“£! )</h1>
<div class=article-metadata>
<div>
<span>
<a href=/author/jinming-zhuang/>Jinming Zhuang</a></span>, <span>
<a href=/author/shaojie-xiang/>Shaojie Xiang</a></span>, <span>
<a href=/author/hongzheng-chen/>Hongzheng Chen</a></span>, <span>
<a href=/author/niansong-zhang/>Niansong Zhang</a></span>, <span>
<a href=/author/zhuoping-yang/>Zhuoping Yang</a></span>, <span>
<a href=/author/tony-mao/>Tony Mao</a></span>, <span>
<a href=/author/zhiru-zhang/>Zhiru Zhang</a></span>, <span class=author-highlighted>
<a href=/author/peipei-zhou/>Peipei Zhou</a></span>
</div>
<span class=article-date>
January 2025
</span>
</div>
<div class="btn-links mb-3">
<a href=# class="btn btn-outline-primary btn-page-header js-cite-modal" data-filename=/publication/2025_fpga_aries/cite.bib>
Cite
</a>
<a class="btn btn-outline-primary btn-page-header" href=https://dl.acm.org/doi/pdf/10.1145/3706628.3708870 target=_blank rel=noopener>
PDF
</a>
<a class="btn btn-outline-primary btn-page-header" href=https://github.com/arc-research-lab/Aries target=_blank rel=noopener>
Code
</a>
<a class="btn btn-outline-primary btn-page-header" href=/publication/2025_fpga_aries/FPGA25_ARIES_Slides_ShareVersion.pdf>
Slides
</a>
</div>
</div>
<div class=article-container>
<h3>Abstract</h3>
<p class=pub-abstract><p>As AI continues to grow, modern applications are becoming more data- and compute-intensive, driving the development of specialized AI chips to meet these demands. One example is AMD&rsquo;s AI Engine (AIE), a dedicated hardware system that includes a 2D array of high-frequency very-long instruction words (VLIW) vector processors to provide high computational throughput and reconfigurability. However, AIE&rsquo;s specialized architecture presents tremendous challenges in programming and compiler optimization. Existing AIE programming frameworks lack a clean abstraction to represent multi-level parallelism in AIE; programmers have to figure out the parallelism within a kernel, manually do the partition, and assign sub-tasks to different AIE cores to exploit parallelism. These significantly lower the programming productivity. Furthermore, some AIE architectures include FPGAs to provide extra flexibility, but there is no unified intermediate representation (IR) that captures these architectural differences. As a result, existing compilers can only optimize the AIE portions of the code, overlooking potential FPGA bottlenecks and leading to suboptimal performance.</p>
<p>To address these limitations, we introduce ARIES, an agile multilevel intermediate representation (MLIR) based compilation flow for reconfigurable devices with AIEs. ARIES introduces a novel programming model that allows users to map kernels to separate AIE cores, exploiting task- and tile-level parallelism without restructuring code. It also includes a declarative scheduling interface to explore instruction-level parallelism within each core. At the IR level, we propose a unified MLIR-based representation for AIE architectures, both with or without FPGA, facilitating holistic optimization and better portability across AIE device families. For the General Matrix Multiply (GEMM) benchmark, ARIES achieves 4.92 TFLOPS, 15.86 TOPS, and 45.94 TOPS throughput under FP32, INT16, and, INT8 data types on Versal VCK190 respectively. Compared with the state-of-the-art (SOTA) work CHARM for AIE, ARIES improves the throughput by 1.17x, 1.59x, and 1.47x correspondingly. For ResNet residual layer, ARIES achieves up to 22.58x speedup compared with optimized SOTA work Riallto on Ryzen-AI NPU. ARIES is opensourced on GitHub: <a href=https://github.com/arc-research-lab/Aries>https://github.com/arc-research-lab/Aries</a>.</p>
</p>
<div class=row>
<div class=col-md-1></div>
<div class=col-md-10>
<div class=row>
<div class="col-12 col-md-3 pub-row-heading">Type</div>
<div class="col-12 col-md-9">
<a href=/publication/#1>
Conference paper
</a>
</div>
</div>
</div>
<div class=col-md-1></div>
</div>
<div class="d-md-none space-below"></div>
<div class=row>
<div class=col-md-1></div>
<div class=col-md-10>
<div class=row>
<div class="col-12 col-md-3 pub-row-heading">Publication</div>
<div class="col-12 col-md-9">Proceedings of the 2025 ACM/SIGDA International Symposium on Field Programmable Gate Arrays, FPGA 2025, Feb. 28 - March 3, Monterey, CA, US. Full Paper Accepted! <a href=https://dl.acm.org/doi/10.1145/3706628.3708870>https://dl.acm.org/doi/10.1145/3706628.3708870</a></div>
</div>
</div>
<div class=col-md-1></div>
</div>
<div class="d-md-none space-below"></div>
<div class=space-below></div>
<div class=article-style></div>
<div class=article-tags>
<a class="badge badge-light" href=/tag/fpga/>FPGA</a>
</div>
<div class=share-box aria-hidden=true>
<ul class=share>
<li>
<a href="https://twitter.com/intent/tweet?url=https://peipeizhou-eecs.github.io/publication/2025_fpga_aries/&text=ARIES:%20An%20Agile%20MLIR-Based%20Compilation%20Flow%20for%20Reconfigurable%20Devices%20with%20AI%20Engines%28%f0%9f%94%a5%f0%9f%93%a3%20FPGA%202025%20Best%20Paper%20Candidate%f0%9f%94%a5%f0%9f%93%a3!%20%29" target=_blank rel=noopener class=share-btn-twitter>
<i class="fab fa-twitter"></i>
</a>
</li>
<li>
<a href="https://www.facebook.com/sharer.php?u=https://peipeizhou-eecs.github.io/publication/2025_fpga_aries/&t=ARIES:%20An%20Agile%20MLIR-Based%20Compilation%20Flow%20for%20Reconfigurable%20Devices%20with%20AI%20Engines%28%f0%9f%94%a5%f0%9f%93%a3%20FPGA%202025%20Best%20Paper%20Candidate%f0%9f%94%a5%f0%9f%93%a3!%20%29" target=_blank rel=noopener class=share-btn-facebook>
<i class="fab fa-facebook"></i>
</a>
</li>
<li>
<a href="mailto:?subject=ARIES:%20An%20Agile%20MLIR-Based%20Compilation%20Flow%20for%20Reconfigurable%20Devices%20with%20AI%20Engines%28%f0%9f%94%a5%f0%9f%93%a3%20FPGA%202025%20Best%20Paper%20Candidate%f0%9f%94%a5%f0%9f%93%a3!%20%29&body=https://peipeizhou-eecs.github.io/publication/2025_fpga_aries/" target=_blank rel=noopener class=share-btn-email>
<i class="fas fa-envelope"></i>
</a>
</li>
<li>
<a href="https://www.linkedin.com/shareArticle?url=https://peipeizhou-eecs.github.io/publication/2025_fpga_aries/&title=ARIES:%20An%20Agile%20MLIR-Based%20Compilation%20Flow%20for%20Reconfigurable%20Devices%20with%20AI%20Engines%28%f0%9f%94%a5%f0%9f%93%a3%20FPGA%202025%20Best%20Paper%20Candidate%f0%9f%94%a5%f0%9f%93%a3!%20%29" target=_blank rel=noopener class=share-btn-linkedin>
<i class="fab fa-linkedin-in"></i>
</a>
</li>
<li>
<a href="whatsapp://send?text=ARIES:%20An%20Agile%20MLIR-Based%20Compilation%20Flow%20for%20Reconfigurable%20Devices%20with%20AI%20Engines%28%f0%9f%94%a5%f0%9f%93%a3%20FPGA%202025%20Best%20Paper%20Candidate%f0%9f%94%a5%f0%9f%93%a3!%20%29%20https://peipeizhou-eecs.github.io/publication/2025_fpga_aries/" target=_blank rel=noopener class=share-btn-whatsapp>
<i class="fab fa-whatsapp"></i>
</a>
</li>
<li>
<a href="https://service.weibo.com/share/share.php?url=https://peipeizhou-eecs.github.io/publication/2025_fpga_aries/&title=ARIES:%20An%20Agile%20MLIR-Based%20Compilation%20Flow%20for%20Reconfigurable%20Devices%20with%20AI%20Engines%28%f0%9f%94%a5%f0%9f%93%a3%20FPGA%202025%20Best%20Paper%20Candidate%f0%9f%94%a5%f0%9f%93%a3!%20%29" target=_blank rel=noopener class=share-btn-weibo>
<i class="fab fa-weibo"></i>
</a>
</li>
</ul>
</div>
<div class="media author-card content-widget-hr">
<div class=media-body>
<h5 class=card-title><a href=/author/jinming-zhuang/>Jinming Zhuang</a></h5>
<h6 class=card-subtitle>PhD Graduate Student</h6>
<ul class=network-icon aria-hidden=true>
</ul>
</div>
</div>
<div class="media author-card content-widget-hr">
<div class=media-body>
<h5 class=card-title><a href=/author/zhuoping-yang/>Zhuoping Yang</a></h5>
<h6 class=card-subtitle>PhD Graduate Student</h6>
<ul class=network-icon aria-hidden=true>
</ul>
</div>
</div>
<div class="media author-card content-widget-hr">
<a href=https://peipeizhou-eecs.github.io/><img class="avatar mr-3 avatar-circle" src=/author/peipei-zhou/avatar_hu80b7558909def6d2fb092cd7f28877cb_2616395_270x270_fill_q75_lanczos_center.jpg alt="Peipei Zhou"></a>
<div class=media-body>
<h5 class=card-title><a href=https://peipeizhou-eecs.github.io/>Peipei Zhou</a></h5>
<h6 class=card-subtitle>Assistant Professor of Engineering</h6>
<p class=card-text>My research interests include <strong>Customized Computer Architecture and Programming Abstraction for Health & AI Applications</strong></p>
<ul class=network-icon aria-hidden=true>
<li>
<a href="https://scholar.google.com/citations?user=px_jwFgAAAAJ&hl=en" target=_blank rel=noopener>
<i class="ai ai-google-scholar"></i>
</a>
</li>
<li>
<a href=https://www.linkedin.com/in/zhoupeipei/ target=_blank rel=noopener>
<i class="fab fa-linkedin"></i>
</a>
</li>
<li>
<a href=https://twitter.com/PeipeiZhou_EECS target=_blank rel=noopener>
<i class="fab fa-twitter"></i>
</a>
</li>
<li>
<a href=https://github.com/arc-research-lab target=_blank rel=noopener>
<i class="fab fa-github"></i>
</a>
</li>
</ul>
</div>
</div>
<div class="article-widget content-widget-hr">
<h3>Related</h3>
<ul>
<li><a href=/publication/2024_fpga/>SSR: Spatial Sequential Hybrid Architecture for Latency Throughput Tradeoff in Transformer Acceleration (ðŸ”¥ðŸ“£New Paper & ProjectðŸ”¥ðŸ“£! )</a></li>
<li><a href=/publication/fpga23/>CHARM: Composing Heterogeneous AcceleRators for Matrix Multiply on Versal ACAP Architecture (ðŸ”¥ðŸ“£New Paper & ProjectðŸ”¥ðŸ“£! )</a></li>
<li><a href=/publication/mocha/>MOCHA: Multinode Cost Optimization in Heterogeneous Clouds with Accelerators</a></li>
<li><a href=/publication/2016_fpga/>ARAPrototyper: Enabling Rapid Prototyping and Evaluation for Accelerator-Rich Architecture</a></li>
</ul>
</div>
</div>
</div>
</div>
<div class=page-footer>
<div class=container>
<footer class=site-footer>
<p class=powered-by>
Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> â€” the free, <a href=https://github.com/wowchemy/wowchemy-hugo-modules target=_blank rel=noopener>open source</a> website builder that empowers creators.
</p>
</footer>
</div>
</div>
<div id=modal class="modal fade" role=dialog>
<div class=modal-dialog>
<div class=modal-content>
<div class=modal-header>
<h5 class=modal-title>Cite</h5>
<button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span>
</button>
</div>
<div class=modal-body>
<pre><code class="tex hljs"></code></pre>
</div>
<div class=modal-footer>
<a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank>
<i class="fas fa-copy"></i> Copy
</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank>
<i class="fas fa-download"></i> Download
</a>
<div id=modal-error></div>
</div>
</div>
</div>
</div>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script>
<script src=/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js></script>
<script src=/en/js/wowchemy.min.d68ecd57c0ec1f1f61d65fd568f1c3a0.js></script>
</body>
</html>